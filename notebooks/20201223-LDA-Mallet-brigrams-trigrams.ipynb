{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "l7WeR-r6uf4x"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import (CountVectorizer,\n",
    "                                             TfidfVectorizer)\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "from os import getcwd, path\n",
    "import os\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "#https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "# plotting\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modern_slavery_registry.utils import (sort_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use if autocompletion is not working\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = getcwd()\n",
    "PROJECT_PATH = PROJECT_PATH.replace(\"\\\\notebooks\", \"\")\n",
    "DATA_PATH = PROJECT_PATH + \"\\\\data\"\n",
    "SHEETS_PATH = DATA_PATH + \"\\\\sheets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "19-wl6Uw8GLu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10078 non-NA statements\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(f\"{SHEETS_PATH}\\\\subset_data.xlsx\")\n",
    "data.fillna(\"#NA\", inplace=True)\n",
    "data = data[[\"URL\", \"final_statement_cleaned\"]]\n",
    "n_sentences = len(data)\n",
    "print(f\"Found {n_sentences} non-NA statements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "jSU34WKL8ctQ",
    "outputId": "63b715fb-d36a-4718-9114-3a5b13b01375"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>final_statement_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://img1.wsimg.com/blobby/go/7695baff-3f0f...</td>\n",
       "      <td>km sh foor eum hold europe ltd aldersgate stre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://1spatial.com/who-we-are/legal/modern-s...</td>\n",
       "      <td>modern slavery act policy statement home solut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.shazans.com/slavery-and-human-traf...</td>\n",
       "      <td>slavery human traffic statement shazans shazan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.business-humanrights.org/sites/def...</td>\n",
       "      <td>modern slavery atement atement make pursuant s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.2agriculture.com/wp-content/upload...</td>\n",
       "      <td>fh modern slavery act slavery human traffic st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  https://img1.wsimg.com/blobby/go/7695baff-3f0f...   \n",
       "1  https://1spatial.com/who-we-are/legal/modern-s...   \n",
       "2  https://www.shazans.com/slavery-and-human-traf...   \n",
       "3  https://www.business-humanrights.org/sites/def...   \n",
       "4  https://www.2agriculture.com/wp-content/upload...   \n",
       "\n",
       "                             final_statement_cleaned  \n",
       "0  km sh foor eum hold europe ltd aldersgate stre...  \n",
       "1  modern slavery act policy statement home solut...  \n",
       "2  slavery human traffic statement shazans shazan...  \n",
       "3  modern slavery atement atement make pursuant s...  \n",
       "4  fh modern slavery act slavery human traffic st...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4174187a8a184d9698eab72efaf9ca48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10078 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NGRAMS = (2, 2)\n",
    "ngram = np.max(NGRAMS)\n",
    "ngram_sentences = []\n",
    "\n",
    "for sentence in tqdm(data[\"final_statement_cleaned\"].values):\n",
    "    sentence = sentence.split()\n",
    "    ngram_sentence = []\n",
    "    len_sentence = len(sentence)\n",
    "    for i in range(len_sentence-ngram + 1):\n",
    "        ngram_sentence.append(\" \".join(sentence[i:i+ngram]))\n",
    "#     # preparing ngrams at end of sentence\n",
    "#     for i in range(len_sentence-ngram+1, len_sentence):\n",
    "#         ngram_sentence.append(\" \".join(\n",
    "#             sentence[i:] + [\"$PAD$\"] * (ngram -  len(sentence[i :]))))\n",
    "    ngram_sentences.append(ngram_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['km sh', 'sh foor', 'foor eum', 'eum hold', 'hold europe', 'europe ltd', 'ltd aldersgate', 'aldersgate street', 'street london', 'london ecia', 'ecia hd', 'hd tel', 'tel mail', 'mail keulongen', 'keulongen uk', 'uk kline', 'kline com', 'com modern', 'modern slavery', 'slavery act']\n"
     ]
    }
   ],
   "source": [
    "print(ngram_sentences[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717a2bb9a3224493bcc8efc52887bbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ngram_term_freq = {} # to keep track of term frequency\n",
    "ngram_document_freq = {} # to keep track of document-term frequency\n",
    "ngram_last_doc = {}\n",
    "for i, ngram_sentence in tqdm(enumerate(ngram_sentences)):\n",
    "    for ngram in ngram_sentence:  \n",
    "        if ngram not in ngram_term_freq:\n",
    "            ngram_term_freq[ngram] = 1\n",
    "            ngram_document_freq[ngram] = 1\n",
    "        else:\n",
    "            ngram_term_freq[ngram] += 1\n",
    "            if ngram_last_doc[ngram] != i:\n",
    "                ngram_document_freq[ngram] += 1\n",
    "        ngram_last_doc[ngram] = i\n",
    "        \n",
    "ngram_document_freq = {ngram: freq/n_sentences for ngram, freq in ngram_document_freq.items()} \n",
    "del ngram_last_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 1284373\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocab size: {len(ngram_term_freq)}\") # without padding last ngrams word in each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_freq</th>\n",
       "      <th>doc_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.284373e+06</td>\n",
       "      <td>1.284373e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.797010e+00</td>\n",
       "      <td>3.908479e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.381305e+02</td>\n",
       "      <td>3.576183e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.922604e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.922604e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.922604e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.984521e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.016000e+04</td>\n",
       "      <td>9.295495e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          term_freq      doc_freq\n",
       "count  1.284373e+06  1.284373e+06\n",
       "mean   4.797010e+00  3.908479e-04\n",
       "std    1.381305e+02  3.576183e-03\n",
       "min    1.000000e+00  9.922604e-05\n",
       "25%    1.000000e+00  9.922604e-05\n",
       "50%    1.000000e+00  9.922604e-05\n",
       "75%    2.000000e+00  1.984521e-04\n",
       "max    9.016000e+04  9.295495e-01"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_stat_table = pd.DataFrame({\"ngram\": ngram_term_freq.keys(), \n",
    "                                 \"term_freq\": ngram_term_freq.values(),\n",
    "                                 \"doc_freq\": ngram_document_freq.values()})\n",
    "ngram_stat_table.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "66EntRIr8LwH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-grams vocab size with doc frequency (0.001, 0.1): 59789\n",
      "2-grams vocab size with doc frequency (0.001, 0.1): 4.655 %\n"
     ]
    }
   ],
   "source": [
    "MIN_DF = .001 \n",
    "MAX_DF = .1  \n",
    "ngram = np.max(NGRAMS)\n",
    "ngram_covered = len(ngram_stat_table[ngram_stat_table[\"doc_freq\"].between(MIN_DF, MAX_DF)])\n",
    "print(f\"{ngram}-grams vocab size with doc frequency ({MIN_DF}, {MAX_DF}): \"\n",
    "      f\"{ngram_covered}\")\n",
    "print(f\"{ngram}-grams vocab size with doc frequency ({MIN_DF}, {MAX_DF}): \"\n",
    "      f\"{ngram_covered*100/len(ngram_document_freq):.3f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10078, 59789)\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(ngram_range=NGRAMS, min_df=MIN_DF, max_df=MAX_DF)\n",
    "X = count_vect.fit_transform(data[\"final_statement_cleaned\"].values) \n",
    "print(f\"shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15b6d4e98094982be7b4c96d66e7f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10078 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word2idx = count_vect.vocabulary_\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "data_for_model = []\n",
    "for row in tqdm(X.toarray()):\n",
    "    idxs = np.where(row > 0)\n",
    "    data_for_model.append([(idx, row[idx]) for idx in idxs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build LDA model\n",
    "N_TOPICS = 10\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=data_for_model,\n",
    "                                           id2word=idx2word,\n",
    "                                           num_topics=N_TOPICS, \n",
    "                                           random_state=RANDOM_STATE,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ('0.005*\"follow policies\" + 0.005*\"potential modern\" + 0.005*\"review exist\" + 0.005*\"understand potential\" + 0.005*\"exist suppliers\" + 0.005*\"aim ensure\" + 0.005*\"concern relate\" + 0.005*\"activities supply\" + 0.005*\"risk relate\" + 0.004*\"relate business\"',)\n",
      "\n",
      "1: ('0.003*\"areas supply\" + 0.003*\"professional service\" + 0.003*\"compliance modern\" + 0.002*\"slavery traffic\" + 0.002*\"reduce risk\" + 0.002*\"limit company\" + 0.002*\"occur within\" + 0.002*\"combat modern\" + 0.002*\"end st\" + 0.002*\"assess potential\"',)\n",
      "\n",
      "2: ('0.014*\"espa ol\" + 0.007*\"compliance company\" + 0.007*\"customer care\" + 0.006*\"business organization\" + 0.005*\"relevant employment\" + 0.005*\"mental physical\" + 0.005*\"knowingly support\" + 0.005*\"find involve\" + 0.005*\"comply provision\" + 0.004*\"include reference\"',)\n",
      "\n",
      "3: ('0.006*\"modern day\" + 0.006*\"day slavery\" + 0.005*\"financial conduct\" + 0.005*\"conduct authority\" + 0.004*\"regulate financial\" + 0.004*\"authorize regulate\" + 0.003*\"long stand\" + 0.003*\"gender pay\" + 0.003*\"register england\" + 0.003*\"co uk\"',)\n",
      "\n",
      "4: ('0.006*\"fundamental human\" + 0.006*\"member staff\" + 0.005*\"various form\" + 0.005*\"breach policy\" + 0.005*\"work us\" + 0.005*\"ensure transparency\" + 0.005*\"violation fundamental\" + 0.005*\"slavery crime\" + 0.004*\"deal relationships\" + 0.004*\"slavery part\"',)\n",
      "\n",
      "5: ('0.004*\"risk management\" + 0.003*\"global compact\" + 0.003*\"manage risk\" + 0.003*\"risk base\" + 0.003*\"uk limit\" + 0.002*\"procurement team\" + 0.002*\"include modern\" + 0.002*\"transparency statement\" + 0.002*\"business activities\" + 0.002*\"unite nations\"',)\n",
      "\n",
      "6: ('0.008*\"personal data\" + 0.005*\"personal information\" + 0.004*\"email address\" + 0.004*\"press release\" + 0.004*\"unite state\" + 0.004*\"fran ais\" + 0.003*\"skip main\" + 0.003*\"customer service\" + 0.003*\"main content\" + 0.003*\"data protection\"',)\n",
      "\n",
      "7: ('0.006*\"live wage\" + 0.005*\"recruitment policy\" + 0.004*\"internal policies\" + 0.004*\"policy set\" + 0.003*\"continue take\" + 0.003*\"minimum wage\" + 0.003*\"control place\" + 0.003*\"policy include\" + 0.003*\"policies ensure\" + 0.003*\"equal opportunities\"',)\n",
      "\n",
      "8: ('0.004*\"code business\" + 0.003*\"direct suppliers\" + 0.003*\"use force\" + 0.003*\"audit suppliers\" + 0.003*\"corrective action\" + 0.002*\"conflict minerals\" + 0.002*\"risk human\" + 0.002*\"regard slavery\" + 0.002*\"labor child\" + 0.002*\"social compliance\"',)\n",
      "\n",
      "9: ('0.011*\"ethical trade\" + 0.005*\"responsible source\" + 0.004*\"stronger together\" + 0.004*\"tier suppliers\" + 0.004*\"work group\" + 0.003*\"tackle modern\" + 0.003*\"base code\" + 0.003*\"ethical audit\" + 0.003*\"trade initiative\" + 0.003*\"labor providers\"',)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in lda_model.print_topics():\n",
    "    print(f\"{topic[0]}: {topic[1:]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_texts = [['interface', 'computer', 'computer', 'computer'],\n",
    "#                 ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
    "#                 ['eps', 'user', 'interface', 'system'],\n",
    "#                 ['system', 'system', 'eps'],\n",
    "#                 ['user', 'response', 'time'],\n",
    "#                 ['trees'],\n",
    "#                 ['graph', 'trees', 'zebra'],\n",
    "#                 ['graph', 'minors', 'trees', 'you', 'you', 'you'],\n",
    "#                 ['graph', 'minors', 'survey', 'human', 'human', 'human', 'human', 'human', 'human', 'human', 'human']]\n",
    "# common_dictionary = corpora.Dictionary(common_texts)\n",
    "# [common_dictionary.doc2bow(text) for text in common_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_path = PROJECT_PATH + \"\\\\models\\\\mallet-2.0.8\"\n",
    "os.environ['MALLET_HOME'] = mallet_path \n",
    "mallet_path = mallet_path + \"\\\\bin\\\\mallet.bat\"\n",
    "\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, \n",
    "                                             corpus=data_for_model,\n",
    "                                             num_topics=N_TOPICS,\n",
    "                                             id2word=idx2word, \n",
    "                                             random_seed=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ('nan*\"promote use\" + nan*\"promote understand\" + nan*\"promote workplace\" + nan*\"promote work\" + nan*\"promote welfare\" + nan*\"promote value\" + nan*\"promotion human\" + nan*\"promote support\" + nan*\"promote ten\" + nan*\"promotional goods\"',)\n",
      "\n",
      "1: ('nan*\"promote use\" + nan*\"promote understand\" + nan*\"promote workplace\" + nan*\"promote work\" + nan*\"promote welfare\" + nan*\"promote value\" + nan*\"promotion human\" + nan*\"promote support\" + nan*\"promote ten\" + nan*\"promotional goods\"',)\n",
      "\n",
      "2: ('nan*\"promote use\" + nan*\"promote understand\" + nan*\"promote workplace\" + nan*\"promote work\" + nan*\"promote welfare\" + nan*\"promote value\" + nan*\"promotion human\" + nan*\"promote support\" + nan*\"promote ten\" + nan*\"promotional goods\"',)\n",
      "\n",
      "3: ('nan*\"promote use\" + nan*\"promote understand\" + nan*\"promote workplace\" + nan*\"promote work\" + nan*\"promote welfare\" + nan*\"promote value\" + nan*\"promotion human\" + nan*\"promote support\" + nan*\"promote ten\" + nan*\"promotional goods\"',)\n",
      "\n",
      "4: ('nan*\"promote use\" + nan*\"promote understand\" + nan*\"promote workplace\" + nan*\"promote work\" + nan*\"promote welfare\" + nan*\"promote value\" + nan*\"promotion human\" + nan*\"promote support\" + nan*\"promote ten\" + nan*\"promotional goods\"',)\n",
      "\n",
      "5: ('nan*\"promote use\" + nan*\"promote understand\" + nan*\"promote workplace\" + nan*\"promote work\" + nan*\"promote welfare\" + nan*\"promote value\" + nan*\"promotion human\" + nan*\"promote support\" + nan*\"promote ten\" + nan*\"promotional goods\"',)\n",
      "\n",
      "6: ('nan*\"promote use\" + nan*\"promote understand\" + nan*\"promote workplace\" + nan*\"promote work\" + nan*\"promote welfare\" + nan*\"promote value\" + nan*\"promotion human\" + nan*\"promote support\" + nan*\"promote ten\" + nan*\"promotional goods\"',)\n",
      "\n",
      "7: ('nan*\"promote use\" + nan*\"promote understand\" + nan*\"promote workplace\" + nan*\"promote work\" + nan*\"promote welfare\" + nan*\"promote value\" + nan*\"promotion human\" + nan*\"promote support\" + nan*\"promote ten\" + nan*\"promotional goods\"',)\n",
      "\n",
      "8: ('nan*\"promote use\" + nan*\"promote understand\" + nan*\"promote workplace\" + nan*\"promote work\" + nan*\"promote welfare\" + nan*\"promote value\" + nan*\"promotion human\" + nan*\"promote support\" + nan*\"promote ten\" + nan*\"promotional goods\"',)\n",
      "\n",
      "9: ('nan*\"promote use\" + nan*\"promote understand\" + nan*\"promote workplace\" + nan*\"promote work\" + nan*\"promote welfare\" + nan*\"promote value\" + nan*\"promotion human\" + nan*\"promote support\" + nan*\"promote ten\" + nan*\"promotional goods\"',)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\modern_slavery\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py:448: RuntimeWarning: invalid value encountered in true_divide\n",
      "  topic = topic / topic.sum()  # normalize to probability dist\n"
     ]
    }
   ],
   "source": [
    "for topic in ldamallet.show_topics():\n",
    "    print(f\"{topic[0]}: {topic[1:]}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "20201203-Topic-Modelling-Slavery-Statements.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "modern_slavery",
   "language": "python",
   "name": "modern_slavery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
