{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import getcwd, path\n",
    "import urllib\n",
    "import pickle\n",
    "from time import sleep\n",
    "import functools\n",
    "from func_timeout import func_timeout, FunctionTimedOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'modern_slavery'\n",
    "PROJECT_PATH = f\"{getcwd()[:getcwd().find(PROJECT_NAME)]}{PROJECT_NAME}\"\n",
    "DATA_PATH = f\"{PROJECT_PATH}\\\\data\"\n",
    "SHEET_PATH = f\"{DATA_PATH}\\\\sheets\"\n",
    "PICKLE_PATH = f\"{DATA_PATH}\\\\pickles\"\n",
    "PDF_PATH = f\"{DATA_PATH}\\\\pdfs\"\n",
    "MAX_DOWNLOAD_TIME = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(obj, file_name):\n",
    "    pickle.dump(obj, file=open(f\"{file_name}.pickle\",\"wb\"))\n",
    "    \n",
    "def load_pickle(file_name):\n",
    "    return pickle.load(file=open(f\"{file_name}.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\RA Work\\RA - Prof. Shawn Bhimani\\modern_slavery\\data\\pickles\\saved_SIDs exists, found - 11044\n",
      "E:\\RA Work\\RA - Prof. Shawn Bhimani\\modern_slavery\\data\\pickles\\failed_SIDs exists, found - 4139\n",
      "E:\\RA Work\\RA - Prof. Shawn Bhimani\\modern_slavery\\data\\pickles\\pdf_not_found_SIDs exists, found - 2471\n",
      "E:\\RA Work\\RA - Prof. Shawn Bhimani\\modern_slavery\\data\\pickles\\timeout_SIDs exists, found - 265\n"
     ]
    }
   ],
   "source": [
    "pickle_name = f\"{PICKLE_PATH}\\\\saved_SIDs\"\n",
    "if path.exists(f\"{pickle_name}.pickle\"):\n",
    "    saved_SIDs = load_pickle(pickle_name)\n",
    "    print(f\"{pickle_name} exists, found - {len(saved_SIDs)}\")\n",
    "else:\n",
    "    saved_SIDs = []\n",
    "    save_pickle(saved_SIDs, file_name=pickle_name)\n",
    "    \n",
    "    \n",
    "pickle_name = f\"{PICKLE_PATH}\\\\failed_SIDs\"\n",
    "if path.exists(f\"{pickle_name}.pickle\"):\n",
    "    failed_SIDs = load_pickle(pickle_name)\n",
    "    print(f\"{pickle_name} exists, found - {len(failed_SIDs)}\")\n",
    "else:\n",
    "    failed_SIDs = []\n",
    "    save_pickle(failed_SIDs, file_name=pickle_name)\n",
    "    print(f\"{pickle_name} created\")\n",
    "    \n",
    "pickle_name = f\"{PICKLE_PATH}\\\\pdf_not_found_SIDs\"\n",
    "if path.exists(f\"{pickle_name}.pickle\"):\n",
    "    pdf_not_found_SIDs = load_pickle(pickle_name)\n",
    "    print(f\"{pickle_name} exists, found - {len(pdf_not_found_SIDs)}\")\n",
    "else:\n",
    "    pdf_not_found_SIDs = []\n",
    "    save_pickle(pdf_not_found_SIDs, file_name=pickle_name)\n",
    "    print(f\"{pickle_name} created\")\n",
    "    \n",
    "pickle_name = f\"{PICKLE_PATH}\\\\timeout_SIDs\"\n",
    "if path.exists(f\"{pickle_name}.pickle\"):\n",
    "    timeout_SIDs = load_pickle(pickle_name)\n",
    "    print(f\"{pickle_name} exists, found - {len(timeout_SIDs)}\")\n",
    "else:\n",
    "    timeout_SIDs = []\n",
    "    save_pickle(timeout_SIDs, file_name=pickle_name)\n",
    "    print(f\"{pickle_name} created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company ID</th>\n",
       "      <th>Company</th>\n",
       "      <th>Is Publisher</th>\n",
       "      <th>Statement ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Override URL</th>\n",
       "      <th>Companies House Number</th>\n",
       "      <th>Industry</th>\n",
       "      <th>HQ</th>\n",
       "      <th>Is Also Covered</th>\n",
       "      <th>UK Modern Slavery Act</th>\n",
       "      <th>California Transparency in Supply Chains Act</th>\n",
       "      <th>Australia Modern Slavery Act</th>\n",
       "      <th>Period Covered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7676</td>\n",
       "      <td>\"K\" Line Holding Europe Limited</td>\n",
       "      <td>True</td>\n",
       "      <td>35092</td>\n",
       "      <td>https://img1.wsimg.com/blobby/go/7695baff-3f0f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05005018</td>\n",
       "      <td>Marine</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28660</td>\n",
       "      <td>\"K\" Line Bulk Shipping (UK) Limited</td>\n",
       "      <td>False</td>\n",
       "      <td>35092</td>\n",
       "      <td>https://img1.wsimg.com/blobby/go/7695baff-3f0f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04830352</td>\n",
       "      <td>Marine</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28659</td>\n",
       "      <td>\"K\" Line (Europe) Limited</td>\n",
       "      <td>False</td>\n",
       "      <td>35092</td>\n",
       "      <td>https://img1.wsimg.com/blobby/go/7695baff-3f0f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05639474</td>\n",
       "      <td>Marine</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28661</td>\n",
       "      <td>\"K\" Line LNG Shipping Limited</td>\n",
       "      <td>False</td>\n",
       "      <td>35092</td>\n",
       "      <td>https://img1.wsimg.com/blobby/go/7695baff-3f0f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marine</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28658</td>\n",
       "      <td>Polar LNG Shipping (UK) Limited</td>\n",
       "      <td>False</td>\n",
       "      <td>35092</td>\n",
       "      <td>https://img1.wsimg.com/blobby/go/7695baff-3f0f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02205323</td>\n",
       "      <td>Marine</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company ID                              Company  Is Publisher  \\\n",
       "0        7676      \"K\" Line Holding Europe Limited          True   \n",
       "1       28660  \"K\" Line Bulk Shipping (UK) Limited         False   \n",
       "2       28659            \"K\" Line (Europe) Limited         False   \n",
       "3       28661        \"K\" Line LNG Shipping Limited         False   \n",
       "4       28658      Polar LNG Shipping (UK) Limited         False   \n",
       "\n",
       "   Statement ID                                                URL  \\\n",
       "0         35092  https://img1.wsimg.com/blobby/go/7695baff-3f0f...   \n",
       "1         35092  https://img1.wsimg.com/blobby/go/7695baff-3f0f...   \n",
       "2         35092  https://img1.wsimg.com/blobby/go/7695baff-3f0f...   \n",
       "3         35092  https://img1.wsimg.com/blobby/go/7695baff-3f0f...   \n",
       "4         35092  https://img1.wsimg.com/blobby/go/7695baff-3f0f...   \n",
       "\n",
       "  Override URL Companies House Number Industry              HQ  \\\n",
       "0          NaN               05005018   Marine  United Kingdom   \n",
       "1          NaN               04830352   Marine  United Kingdom   \n",
       "2          NaN               05639474   Marine  United Kingdom   \n",
       "3          NaN                    NaN   Marine  United Kingdom   \n",
       "4          NaN               02205323   Marine  United Kingdom   \n",
       "\n",
       "   Is Also Covered  UK Modern Slavery Act  \\\n",
       "0            False                   True   \n",
       "1             True                   True   \n",
       "2             True                   True   \n",
       "3             True                   True   \n",
       "4             True                   True   \n",
       "\n",
       "   California Transparency in Supply Chains Act  Australia Modern Slavery Act  \\\n",
       "0                                         False                         False   \n",
       "1                                         False                         False   \n",
       "2                                         False                         False   \n",
       "3                                         False                         False   \n",
       "4                                         False                         False   \n",
       "\n",
       "  Period Covered  \n",
       "0      2018-2019  \n",
       "1      2018-2019  \n",
       "2      2018-2019  \n",
       "3      2018-2019  \n",
       "4      2018-2019  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{DATA_PATH}\\modernslaveryregistry-2020-09-14.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total enteries : 27531, total unique statements : 17799\n"
     ]
    }
   ],
   "source": [
    "TOTAL_UNIQUE_SIDs = len(np.unique(df['Statement ID'].values))\n",
    "print(f\"Total enteries : {len(df)}, \"\n",
    "      f\"total unique statements : {TOTAL_UNIQUE_SIDs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(url, sid):\n",
    "    response = urllib.request.urlopen(url=url)\n",
    "    file_name = f\"SID-{statement_id}\"\n",
    "    file = open(f\"{PDF_PATH}\\\\{file_name}.pdf\", 'wb')\n",
    "    file.write(response.read())\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (df.drop_duplicates(subset=['Statement ID', 'URL'])[['Statement ID', 'URL']].values):\n",
    "    sid = i[0]\n",
    "    url = i[1]\n",
    "    if sid in saved_SIDs:\n",
    "        print(f\"Already downloaded for SID - {sid}\")\n",
    "    elif sid in failed_SIDs:\n",
    "        print(f\"Already downloading failed for SID - {sid}\")\n",
    "    elif sid in timeout_SIDs:\n",
    "        print(f\"Already downloading timeout for SID - {sid}\")\n",
    "    else:\n",
    "        try:\n",
    "            doitReturnValue = func_timeout(timeout=MAX_DOWNLOAD_TIME,\n",
    "                                           func=download_pdf, \n",
    "                                           args=[url, sid])\n",
    "            saved_SIDs.append(int(sid))\n",
    "            save_pickle(saved_SIDs, file_name=f\"{PICKLE_PATH}\\\\saved_SIDs\")\n",
    "            print(f\"-Downloaded {len(saved_SIDs)} / {TOTAL_UNIQUE_SIDs}-\")\n",
    "            sleep(1)\n",
    "        except FunctionTimedOut: # when more than MAX_DOWNLOAD_TIME\n",
    "            timeout_SIDs.append(int(sid))\n",
    "            save_pickle(timeout_SIDs, file_name=f\"{PICKLE_PATH}\\\\timeout_SIDs\")\n",
    "            print(f\"-Downloading timeout {len(timeout_SIDs)} / {TOTAL_UNIQUE_SIDs}-\")\n",
    "            continue \n",
    "        except:\n",
    "            failed_SIDs.append(int(sid))\n",
    "            save_pickle(failed_SIDs, file_name=f\"{PICKLE_PATH}\\\\failed_SIDs\")\n",
    "            print(f\"-Downloading failed {len(failed_SIDs)} / {TOTAL_UNIQUE_SIDs}-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to get not saved pdfs\n",
    "# new_df = df[~df['Statement ID'].isin(saved_SIDs)].copy()\n",
    "new_df = df.copy()\n",
    "new_df = new_df.drop_duplicates(\n",
    "    subset=['Statement ID', 'URL']\n",
    ")[['Statement ID', 'URL']].values\n",
    "# failed_SIDs = []\n",
    "# pdf_not_found_SIDs = []\n",
    "# timeout_SIDs = []\n",
    "# print(f\"Try again for - {len(new_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(new_df):\n",
    "    print(f\"\\n No. {i}/{TOTAL_UNIQUE_SIDs}\")\n",
    "    sid = row[0]\n",
    "    url = row[1]\n",
    "    if sid in saved_SIDs:\n",
    "        print(f\"Already downloaded for SID - {sid}, \"\n",
    "              f\"{len(saved_SIDs)}/{TOTAL_UNIQUE_SIDs}\")\n",
    "    elif sid in pdf_not_found_SIDs:\n",
    "        print(f\"PDF not found for SID - {sid}, \"\n",
    "              f\"{len(pdf_not_found_SIDs)}/{TOTAL_UNIQUE_SIDs}\")\n",
    "    elif sid in failed_SIDs:\n",
    "        print(f\"Already failed downloading for SID - {sid}, \"\n",
    "              f\"{len(failed_SIDs)}/{TOTAL_UNIQUE_SIDs}\")\n",
    "    elif sid in timeout_SIDs:\n",
    "        print(f\"Already timeout downloading for SID - {sid}, \" \n",
    "              f\"{len(timeout_SIDs)}/{TOTAL_UNIQUE_SIDs}\")\n",
    "    else:\n",
    "        try:\n",
    "            doitReturnValue = func_timeout(timeout=MAX_DOWNLOAD_TIME,\n",
    "                                           func=download_pdf, \n",
    "                                           args=[url, sid]) # if timeout\n",
    "            saved_SIDs.append(int(sid))\n",
    "            save_pickle(saved_SIDs, file_name=f\"{PICKLE_PATH}\\\\saved_SIDs\")\n",
    "            print(f\"Downloaded - {len(saved_SIDs)} / {TOTAL_UNIQUE_SIDs}\")\n",
    "            sleep(1)\n",
    "        except FunctionTimedOut: # when more than MAX_DOWNLOAD_TIME\n",
    "            timeout_SIDs.append(int(sid))\n",
    "            save_pickle(timeout_SIDs, file_name=f\"{PICKLE_PATH}\\\\timeout_SIDs\")\n",
    "            print(f\"Downloading timeout - {len(timeout_SIDs)} / {TOTAL_UNIQUE_SIDs}\")\n",
    "        except urllib.error.HTTPError as HTTPErrror:\n",
    "            if 'HTTP Error 404: Not Found' in str(HTTPErrror):\n",
    "                pdf_not_found_SIDs.append(int(sid))\n",
    "                save_pickle(pdf_not_found_SIDs, file_name=f\"{PICKLE_PATH}\\\\pdf_not_found_SIDs\")\n",
    "                print(f\"PDF not found - {len(pdf_not_found_SIDs)} / {TOTAL_UNIQUE_SIDs}\")\n",
    "            else:\n",
    "                failed_SIDs.append(int(sid))\n",
    "                save_pickle(failed_SIDs, file_name=f\"{PICKLE_PATH}\\\\failed_SIDs\")\n",
    "                print(f\"Downloading failed - {len(failed_SIDs)} / {TOTAL_UNIQUE_SIDs}\")\n",
    "        except:\n",
    "            failed_SIDs.append(int(sid))\n",
    "            save_pickle(failed_SIDs, file_name=f\"{PICKLE_PATH}\\\\failed_SIDs\")\n",
    "            print(f\"Downloading failed - {len(failed_SIDs)} / {TOTAL_UNIQUE_SIDs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdfurl(sid):\n",
    "    return df[df['Statement ID']==sid]['URL'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9224-https://www.eurocompliance.co.uk/about-us/policies-and-compliance/\n"
     ]
    }
   ],
   "source": [
    "random_sid = np.random.choice(pdf_not_found_SIDs)\n",
    "print(f\"{random_sid}-{get_pdfurl(random_sid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PDF download :    11044  / 17799\n",
      "Total PDF not found :   2471  / 17799\n",
      "Total failed download : 4139 / 17799\n",
      "Total timeout download: 265/ 17799\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total PDF download :    {len(saved_SIDs)}  / {TOTAL_UNIQUE_SIDs}\")\n",
    "print(f\"Total PDF not found :   {len(pdf_not_found_SIDs)}  / {TOTAL_UNIQUE_SIDs}\")\n",
    "print(f\"Total failed download : {len(failed_SIDs)} / {TOTAL_UNIQUE_SIDs}\")\n",
    "print(f\"Total timeout download: {len(timeout_SIDs)}/ {TOTAL_UNIQUE_SIDs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17919"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(saved_SIDs + pdf_not_found_SIDs + failed_SIDs + timeout_SIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2471, 3662)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = df[df['Statement ID'].isin(pdf_not_found_SIDs)][['Statement ID', 'URL']]\n",
    "len(t.drop_duplicates()), len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Statement ID'].isin(\n",
    "    pdf_not_found_SIDs)\n",
    "  ].to_excel(f\"{SHEET_PATH}\\modernslaveryregistry_pdf_not_found.xlsx\", \n",
    "             index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modern-slavery",
   "language": "python",
   "name": "modern-slavery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
