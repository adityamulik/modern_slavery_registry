{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used to extract text from PDFs\n",
    "\n",
    "Tika is used to extract text from PDFs - drawback is unable to extract from image converted PDFs\n",
    "\n",
    "Note - to use tika, java jdk is required and tika-server-1.24.1.jar is required to be run using `javac -jar tika-server-1.24.1.jar` \n",
    "link to download tika-server : `https://downloads.apache.org/tika/tika-server-1.24.1.jar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import getcwd, path\n",
    "import urllib\n",
    "import pickle\n",
    "from time import sleep\n",
    "import functools\n",
    "import PyPDF2\n",
    "import glob\n",
    "from func_timeout import func_timeout, FunctionTimedOut\n",
    "import re\n",
    "from langdetect import detect\n",
    "from langdetect import lang_detect_exception\n",
    "\n",
    "from tika import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'modern_slavery_registry'\n",
    "PROJECT_PATH = f\"{getcwd()[:getcwd().find(PROJECT_NAME)]}{PROJECT_NAME}\"\n",
    "DATA_PATH = f\"{PROJECT_PATH}\\\\data\"\n",
    "PICKLE_PATH = f\"{DATA_PATH}\\\\pickles\"\n",
    "PDF_PATH = f\"{DATA_PATH}\\\\pdfs\"\n",
    "TEXT_PATH = f\"{DATA_PATH}\\\\texts\"\n",
    "PROCESSED_TEXT_PATH = f\"{DATA_PATH}\\\\processed_texts\"\n",
    "MAX_DOWNLOAD_TIME = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(obj, file_name):\n",
    "    pickle.dump(obj, file=open(f\"{file_name}.pickle\",\"wb\"))\n",
    "    \n",
    "def load_pickle(file_name):\n",
    "    return pickle.load(file=open(f\"{file_name}.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Projects\\modern_slavery_registry\\data\\pickles\\extracted_text_SIDs exists\n",
      "E:\\Projects\\modern_slavery_registry\\data\\pickles\\failed_text_SIDs exists\n"
     ]
    }
   ],
   "source": [
    "pickle_name = f\"{PICKLE_PATH}\\\\extracted_text_SIDs\"\n",
    "if path.exists(f\"{pickle_name}.pickle\"):\n",
    "    extracted_text_SIDs = load_pickle(pickle_name)\n",
    "    print(f\"{pickle_name} exists\")\n",
    "else:\n",
    "    extracted_text_SIDs = []\n",
    "    save_pickle(extracted_text_SIDs, file_name=pickle_name)\n",
    "    print(f\"{pickle_name} created\")\n",
    "    \n",
    "    \n",
    "pickle_name = f\"{PICKLE_PATH}\\\\failed_text_SIDs\"\n",
    "if path.exists(f\"{pickle_name}.pickle\"):\n",
    "    failed_text_SIDs = load_pickle(pickle_name)\n",
    "    print(f\"{pickle_name} exists\")\n",
    "else:\n",
    "    failed_text_SIDs = []\n",
    "    save_pickle(failed_text_SIDs, file_name=pickle_name)\n",
    "    print(f\"{pickle_name} created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company ID</th>\n",
       "      <th>Company</th>\n",
       "      <th>Is Publisher</th>\n",
       "      <th>Statement ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Override URL</th>\n",
       "      <th>Companies House Number</th>\n",
       "      <th>Industry</th>\n",
       "      <th>HQ</th>\n",
       "      <th>Is Also Covered</th>\n",
       "      <th>UK Modern Slavery Act</th>\n",
       "      <th>California Transparency in Supply Chains Act</th>\n",
       "      <th>Australia Modern Slavery Act</th>\n",
       "      <th>Period Covered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7676</td>\n",
       "      <td>\"K\" Line Holding Europe Limited</td>\n",
       "      <td>True</td>\n",
       "      <td>35092</td>\n",
       "      <td>https://img1.wsimg.com/blobby/go/7695baff-3f0f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05005018</td>\n",
       "      <td>Marine</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28660</td>\n",
       "      <td>\"K\" Line Bulk Shipping (UK) Limited</td>\n",
       "      <td>False</td>\n",
       "      <td>35092</td>\n",
       "      <td>https://img1.wsimg.com/blobby/go/7695baff-3f0f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04830352</td>\n",
       "      <td>Marine</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28659</td>\n",
       "      <td>\"K\" Line (Europe) Limited</td>\n",
       "      <td>False</td>\n",
       "      <td>35092</td>\n",
       "      <td>https://img1.wsimg.com/blobby/go/7695baff-3f0f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05639474</td>\n",
       "      <td>Marine</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28661</td>\n",
       "      <td>\"K\" Line LNG Shipping Limited</td>\n",
       "      <td>False</td>\n",
       "      <td>35092</td>\n",
       "      <td>https://img1.wsimg.com/blobby/go/7695baff-3f0f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marine</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28658</td>\n",
       "      <td>Polar LNG Shipping (UK) Limited</td>\n",
       "      <td>False</td>\n",
       "      <td>35092</td>\n",
       "      <td>https://img1.wsimg.com/blobby/go/7695baff-3f0f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02205323</td>\n",
       "      <td>Marine</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company ID                              Company  Is Publisher  \\\n",
       "0        7676      \"K\" Line Holding Europe Limited          True   \n",
       "1       28660  \"K\" Line Bulk Shipping (UK) Limited         False   \n",
       "2       28659            \"K\" Line (Europe) Limited         False   \n",
       "3       28661        \"K\" Line LNG Shipping Limited         False   \n",
       "4       28658      Polar LNG Shipping (UK) Limited         False   \n",
       "\n",
       "   Statement ID                                                URL  \\\n",
       "0         35092  https://img1.wsimg.com/blobby/go/7695baff-3f0f...   \n",
       "1         35092  https://img1.wsimg.com/blobby/go/7695baff-3f0f...   \n",
       "2         35092  https://img1.wsimg.com/blobby/go/7695baff-3f0f...   \n",
       "3         35092  https://img1.wsimg.com/blobby/go/7695baff-3f0f...   \n",
       "4         35092  https://img1.wsimg.com/blobby/go/7695baff-3f0f...   \n",
       "\n",
       "  Override URL Companies House Number Industry              HQ  \\\n",
       "0          NaN               05005018   Marine  United Kingdom   \n",
       "1          NaN               04830352   Marine  United Kingdom   \n",
       "2          NaN               05639474   Marine  United Kingdom   \n",
       "3          NaN                    NaN   Marine  United Kingdom   \n",
       "4          NaN               02205323   Marine  United Kingdom   \n",
       "\n",
       "   Is Also Covered  UK Modern Slavery Act  \\\n",
       "0            False                   True   \n",
       "1             True                   True   \n",
       "2             True                   True   \n",
       "3             True                   True   \n",
       "4             True                   True   \n",
       "\n",
       "   California Transparency in Supply Chains Act  Australia Modern Slavery Act  \\\n",
       "0                                         False                         False   \n",
       "1                                         False                         False   \n",
       "2                                         False                         False   \n",
       "3                                         False                         False   \n",
       "4                                         False                         False   \n",
       "\n",
       "  Period Covered  \n",
       "0      2018-2019  \n",
       "1      2018-2019  \n",
       "2      2018-2019  \n",
       "3      2018-2019  \n",
       "4      2018-2019  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{DATA_PATH}\\modernslaveryregistry-2020-09-14.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total enteries : 27531, total unique statements : 17799\n"
     ]
    }
   ],
   "source": [
    "UNIQUE_SIDs = np.unique(df['Statement ID'].values)\n",
    "TOTAL_UNIQUE_SIDs = len(UNIQUE_SIDs)\n",
    "print(f\"Total enteries : {len(df)}, \"\n",
    "      f\"total unique statements : {TOTAL_UNIQUE_SIDs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15064 pdfs.\n"
     ]
    }
   ],
   "source": [
    "pdfs = glob.glob(pathname=f\"{PDF_PATH}\\\\*.pdf\")\n",
    "TOTAL_PDFs = len(pdfs)\n",
    "print(f\"Found {TOTAL_PDFs} pdfs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_url_from_sid(sid):\n",
    "    \"\"\"Returns PDF url for input sid.\"\"\"\n",
    "    return df[df['Statement ID']==sid]['URL'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sid_from_filename(file_name):\n",
    "    \"\"\"Extract and return SID from file_name.\"\"\"\n",
    "    return int(re.findall(pattern=r\"[\\d]+\",string=path.basename(file_name))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Clean and return input text.\"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"\\t\", \" \")\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_name):\n",
    "    \"\"\"Extract and return texts from PDFs.\"\"\"\n",
    "    pdf_file_obj = open(pdf_name, 'rb')\n",
    "    pdf_reader = PyPDF2.PdfFileReader(pdf_file_obj)\n",
    "    num_pages = pdf_reader.numPages\n",
    "    text = \"\"\n",
    "    for page in range(num_pages):\n",
    "        page_obj = pdf_reader.getPage(page)\n",
    "        text += page_obj.extractText()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf_using_tika(pdf_name):\n",
    "    \"\"\"Return PDF content using Tika.\"\"\"\n",
    "    return parser.from_file(pdf_name)['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text(text, sid):\n",
    "    \"\"\"Save text in text file.\"\"\"\n",
    "    file_name = f\"SID-{sid}\" \n",
    "    file_obj = open(f\"{TEXT_PATH}//{file_name}.txt\", 'w', encoding='utf-8')\n",
    "    file_obj.write(text)\n",
    "    file_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using PyPDF2\n",
    "# for pdf in pdfs:\n",
    "#     sid = re.findall(pattern=r\"[\\d]+\",string=path.basename(pdf))[0]\n",
    "#     print(f\"Running {len(extracted_text_SIDs) + len(failed_text_SIDs)}/{len(pdfs)}\")\n",
    "#     try:\n",
    "#         text = extract_text_from_pdf(pdf)\n",
    "#         save_text(text=text, sid=sid)\n",
    "#         extracted_text_SIDs.append(int(sid))\n",
    "#         save_pickle(extracted_text_SIDs, file_name=f\"{PICKLE_PATH}\\\\extracted_text_SIDs\")\n",
    "#         print(f\"Extracted text for {len(extracted_text_SIDs)}/{len(pdfs)}\")\n",
    "#     except:\n",
    "#         failed_text_SIDs.append(failed_text_SIDs)\n",
    "#         save_pickle(failed_text_SIDs, file_name=f\"{PICKLE_PATH}\\\\failed_text_SIDs\")\n",
    "#         print(f\"Failed extract for {len(failed_text_SIDs)}/{len(pdfs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_loop_no(total_sids, sid, itr, type_, type_itr):\n",
    "    \"\"\"Print loop statements.\"\"\"\n",
    "    primary_text = f\"Running - {itr}/{total_sids} , SID - {sid}\"\n",
    "    if type_ == \"Success\":\n",
    "        primary_text = f\"{primary_text} - Success - {type_itr}\"\n",
    "    elif type_ == \"Failed\":\n",
    "        primary_text = f\"{primary_text} - Failed - {type_itr}\"\n",
    "    else:\n",
    "        primary_text = f\"{primary_text} - Processed - {type_itr}\"\n",
    "    print(f\"{'-'*8} {primary_text} {'-'*8}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Projects\\\\modern_slavery_registry\\\\data\\\\pdfs'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDF_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_text_from_pdf_using_tika(f\"{PDF_PATH}\\\\SID-{26198}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Tika\n",
    "# Note : start tika-server using java -jar tika-server-1.24.1.jar\n",
    "for i, pdf_name in enumerate(pdfs):\n",
    "    sid = get_sid_from_filename(file_name=pdf_name)\n",
    "    if sid not in extracted_text_SIDs and sid not in failed_text_SIDs:\n",
    "        try:\n",
    "            text = extract_text_from_pdf_using_tika(pdf_name)\n",
    "            text = clean_text(text)\n",
    "            save_text(text=text, sid=sid)\n",
    "            extracted_text_SIDs.append(int(sid))\n",
    "            print_loop_no(total_sids=TOTAL_PDFs,\n",
    "                          sid=sid, \n",
    "                          itr=i+1, \n",
    "                          type_=\"Success\",\n",
    "                          type_itr=len(extracted_text_SIDs))\n",
    "        except:\n",
    "            failed_text_SIDs.append(failed_text_SIDs)\n",
    "            print_loop_no(total_sids=TOTAL_PDFs,\n",
    "                          sid=sid, \n",
    "                          itr=i+1, \n",
    "                          type_=\"Failed\",\n",
    "                          type_itr=len(failed_text_SIDs))\n",
    "    else:\n",
    "        print_loop_no(total_sids=TOTAL_PDFs,\n",
    "                      sid=sid, \n",
    "                      itr=i+1,\n",
    "                      type_=\"Processed\",\n",
    "                      type_itr=len(extracted_text_SIDs)+len(failed_text_SIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"No. of pdf from which texts were extracted :     {len(extracted_text_SIDs)}\")\n",
    "print(f\"No. of pdf from which texts were not extracted : {len(failed_text_SIDs)}\")\n",
    "print(f\"No. of pdf from which texts were not extracted : {len(failed_text_SIDs) + len(extracted_text_SIDs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing PDFs SIDs pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PDFs available       : 15064\n",
      "Total PDFs downloaded      : 11044\n",
      "Total PDFs not found       : 2471\n",
      "Total PDFs failed download : 4020\n",
      "Total PDFs timeout download: 264\n",
      "Total PDFs worked on       : 17799\n"
     ]
    }
   ],
   "source": [
    "pickle_name = f\"{PICKLE_PATH}\\\\saved_SIDs\"\n",
    "saved_SIDs = load_pickle(pickle_name)\n",
    "    \n",
    "pickle_name = f\"{PICKLE_PATH}\\\\failed_SIDs\"\n",
    "failed_SIDs = load_pickle(pickle_name)\n",
    "    \n",
    "pickle_name = f\"{PICKLE_PATH}\\\\pdf_not_found_SIDs\"\n",
    "pdf_not_found_SIDs = load_pickle(pickle_name)\n",
    "    \n",
    "pickle_name = f\"{PICKLE_PATH}\\\\timeout_SIDs\"\n",
    "timeout_SIDs = load_pickle(pickle_name)\n",
    "\n",
    "print(f\"Total PDFs available       : {len(pdfs)}\")\n",
    "print(f\"Total PDFs downloaded      : {len(saved_SIDs)}\")\n",
    "print(f\"Total PDFs not found       : {len(pdf_not_found_SIDs)}\")\n",
    "print(f\"Total PDFs failed download : {len(failed_SIDs)}\")\n",
    "print(f\"Total PDFs timeout download: {len(timeout_SIDs)}\")\n",
    "print(f\"Total PDFs worked on       : {len(saved_SIDs) + len(pdf_not_found_SIDs) + len(failed_SIDs) + len(timeout_SIDs)}\")\n",
    "\n",
    "# failed_SIDs = [i for i in failed_SIDs if i not in saved_SIDs]\n",
    "# pdf_not_found_SIDs = [i for i in pdf_not_found_SIDs if i not in saved_SIDs]\n",
    "# timeout_SIDs = [i for i in timeout_SIDs if i not in saved_SIDs]\n",
    "\n",
    "# pickle_name = f\"{PICKLE_PATH}\\\\saved_SIDs\"\n",
    "# save_pickle(saved_SIDs, file_name=pickle_name)\n",
    "    \n",
    "# pickle_name = f\"{PICKLE_PATH}\\\\failed_SIDs\"\n",
    "# save_pickle(failed_SIDs, file_name=pickle_name)\n",
    "\n",
    "# pickle_name = f\"{PICKLE_PATH}\\\\pdf_not_found_SIDs\"\n",
    "# save_pickle(pdf_not_found_SIDs, file_name=pickle_name)\n",
    "    \n",
    "# pickle_name = f\"{PICKLE_PATH}\\\\timeout_SIDs\"\n",
    "# save_pickle(timeout_SIDs, file_name=pickle_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14309 text files\n"
     ]
    }
   ],
   "source": [
    "text_files = glob.glob(pathname=f\"{TEXT_PATH}\\\\*.txt\")\n",
    "TOTAL_TEXT_FILES = len(text_files)\n",
    "print(f\"Found {TOTAL_TEXT_FILES} text files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modern-slavery",
   "language": "python",
   "name": "modern-slavery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
