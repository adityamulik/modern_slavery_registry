{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use if autocompletion is not working\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from typing import List, Tuple, Dict, Union\n",
    "from collections import OrderedDict\n",
    "from nltk import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modern_slavery_registry import get_root_path\n",
    "# from modern_slavery_registry.modern_slavery_statement_parser import clean_text, clean_corpus\n",
    "from modern_slavery_registry import text_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = get_root_path()\n",
    "DATA_PATH = os.path.join(PROJECT_PATH, \"data\")\n",
    "SHEETS_PATH = os.path.join(PROJECT_PATH, \"data\", \"sheets\")\n",
    "PLOTS_PATH = os.path.join(PROJECT_PATH, \"plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(os.listdir(SHEETS_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping continents to country codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(os.path.join(SHEETS_PATH, \"subset_data_v7.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[col for col in df.columns if \"statement\" in col]].isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(\"#NA\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# cleaned_corpus = clean_corpus(corpus=df[\"statement\"].values)\n",
    "\n",
    "# cleaned_corpus_as_list = []\n",
    "# for i in range(len(cleaned_corpus)):\n",
    "#     cleaned_corpus_as_list.append(deepcopy(cleaned_corpus[i]))\n",
    "    \n",
    "# del cleaned_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_process_freqs(\n",
    "    corpus: Union[np.ndarray, List[str]], \n",
    "    ngram: int) -> Dict[str, int]:\n",
    "    \"\"\"Compute ngram frequency from corpus.\"\"\"\n",
    "    freqs = text_parser.compute_ngram_freqs(\n",
    "        corpus=corpus, \n",
    "        n=ngram, \n",
    "        verbose=True)\n",
    "    \n",
    "    new_freqs = OrderedDict()\n",
    "    for k, v in freqs.items():\n",
    "        k = re.sub(r\"[.,:;?]+\", \"\", \" \".join(k))\n",
    "        k = \" \".join(k.split())\n",
    "        if len(k) > 0: \n",
    "            new_freqs[k] = v \n",
    "            \n",
    "    del freqs\n",
    "    new_freqs = {\n",
    "        k:v for k,v in sorted(new_freqs.items(), key=lambda x: x[1], reverse=True)}\n",
    "    \n",
    "    return new_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NGRAMS analysis on basis of continents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continents = [col for col in df.columns if col.startswith(\"HQ_Continent\")]\n",
    "continents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting wordclouds per continent\n",
    "MAX_WORDS = 200 \n",
    "for continent in tqdm(continents, leave=False, position=0):\n",
    "    freqs = compute_and_process_freqs(\n",
    "        df[df[continent]==1][\"statement_cleaned_v2\"].values, ngram=1)\n",
    "    wd = WordCloud(width=1800, height=1200, background_color=\"white\", max_words=MAX_WORDS)\n",
    "    wd.generate_from_frequencies(frequencies=freqs)\n",
    "    fig, ax = plt.subplots(figsize=(12,12))\n",
    "    title = f\"Top {MAX_WORDS} words wordcloud for {continent}\"\n",
    "    ax.set_title(title)\n",
    "    ax.imshow(wd)\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOTS_PATH, \"_\".join(title.split())))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,10), ncols=6, sharey=True)\n",
    "for continent, ax in tqdm(zip(continents, axes.flatten()), leave=False, position=0):\n",
    "    values = df[df[continent]==1][\"statement_cleaned_v2\"].values\n",
    "    lens = [len(statement.split()) for statement in values]\n",
    "    ax.boxplot(lens)\n",
    "    ax.set_title(f\"{continent.replace('_',' ').split()[-1]}: {len(values)} statements\")\n",
    "    sns.despine(ax=ax)\n",
    "fig.text(x=.5, y=.98, s=\"Distribution of number of words in statements by continents\", ha=\"center\")\n",
    "plt.tight_layout(pad=2)\n",
    "plt.savefig(os.path.join(\n",
    "    PLOTS_PATH,\n",
    "    \"Distribution_Number_of_Words_HQ_Continents\"),\n",
    "            dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # computing ngrams on basis of continents\n",
    "# cols = [col for col in df.columns if col.startswith(\"HQ_Continent\")]\n",
    "# ngrams = [1,2,3]\n",
    "\n",
    "# freqs = {}\n",
    "# for col in cols:\n",
    "#     col_freqs = {}\n",
    "#     for ngram in ngrams:\n",
    "#         col_freqs[ngram] = compute_and_process_freqs(\n",
    "#             df[df[col]==1][\"statement_cleaned_v2\"].values, \n",
    "#             ngram=ngram)\n",
    "#     freqs[col] = deepcopy(col_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plotting ngrams over all available continents\n",
    "# top_n = 25\n",
    "# fig, axes = plt.subplots(\n",
    "#     nrows=2,\n",
    "#     ncols=3, \n",
    "#     squeeze=False,\n",
    "#     figsize=(30, 12))\n",
    "# ngram = 3\n",
    "# for col, ax in zip(cols, axes.flatten()):\n",
    "#     pd.DataFrame.from_dict(\n",
    "#         freqs[col][ngram], \n",
    "#         orient=\"index\").head(n).sort_values(0).plot.barh(ax=ax)\n",
    "#     title = f\"{col}\"\n",
    "#     ax.set_title(title)\n",
    "#     ax.get_legend().remove()\n",
    "#     sns.despine(ax=ax)\n",
    "\n",
    "# title = f\"Top-{top_n} {ngram}-gram\"\n",
    "# fig.text(x=.5, y=.92, s=title, ha=\"center\")\n",
    "# plt.savefig(os.path.join(PLOTS_PATH, f\"{title}_by_HQ_Continent.png\"), dpi=200)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # saving top_n ngrams for each continent\n",
    "# save_top_n = 10000\n",
    "# for col in cols:\n",
    "#     for ngram in ngrams:\n",
    "#         name = (\n",
    "#             f\"{col}_{ngram}-gram_\"\n",
    "#             f\"top_{save_top_n}_freq_dist.csv\")\n",
    "#         temp_df = pd.DataFrame.from_dict(\n",
    "#             freqs[col][ngram], \n",
    "#             orient=\"index\").head(\n",
    "#             save_top_n)\n",
    "        \n",
    "#         temp_df.reset_index(inplace=True)\n",
    "#         temp_df.columns = [\"token\", f\"{ngram}-gram_freq\"]\n",
    "#         temp_df.to_csv(\n",
    "#             os.path.join(SHEETS_PATH, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NGRAMS analysis on basis of years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = df[\"year\"].value_counts().sort_index(na_position=\"first\")\n",
    "years.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing freqs by year and ngrams\n",
    "all_freqs = {}\n",
    "ngrams = np.arange(1,4)\n",
    "for ngram in tqdm(ngrams, leave=False, position=0):\n",
    "    year_freqs = {}\n",
    "    for year in years.index:\n",
    "        values = df[df[\"year\"]==year][\"statement_cleaned_v2\"].values\n",
    "        num_statements = len(values)\n",
    "        freqs = compute_and_process_freqs(\n",
    "            values, \n",
    "            ngram=ngram)\n",
    "        freqs = pd.DataFrame.from_dict(\n",
    "            freqs, \n",
    "            orient=\"index\").sort_values(0, ascending=False)\n",
    "        year_freqs[year] = (num_statements, freqs)\n",
    "    all_freqs[ngram] = year_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = 3\n",
    "n = 25\n",
    "fig, axes = plt.subplots(\n",
    "        nrows=4, ncols=3,\n",
    "        figsize=(16,20),\n",
    "        squeeze=False)\n",
    "title = f\"Top {n} {ngram}-ngrams by year\"\n",
    "fig.text(x=.6, y=.992, s=title, ha=\"center\")\n",
    "for year, ax in zip(years.index, axes.flatten()):\n",
    "    all_freqs[ngram][year][1].head(n).sort_values(0).plot.barh(ax=ax)\n",
    "    ax.set_title(f\"{int(year)} - {all_freqs[ngram][year][0]} statements\", y=.98, fontdict={\"fontsize\": 10})\n",
    "    ax.get_legend().remove()\n",
    "    sns.despine(ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_PATH, f\"{title}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting wordclouds per year\n",
    "MAX_WORDS = 200 \n",
    "for year in tqdm(years.index, leave=False, position=0):\n",
    "    wd = WordCloud(\n",
    "        width=1800, \n",
    "        height=1200,\n",
    "        background_color=\"white\", \n",
    "        max_words=MAX_WORDS)\n",
    "    wd.generate_from_frequencies(frequencies=all_freqs[1][year][1].to_dict()[0])\n",
    "    fig, ax = plt.subplots(figsize=(12,12))\n",
    "    title = f\"Top {MAX_WORDS} words wordcloud from {int(year)} - {all_freqs[1][year][0]} statements\"\n",
    "    ax.set_title(title)\n",
    "    ax.imshow(wd)\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    fp = title = f\"Top {MAX_WORDS} words wordcloud from {int(year)}\"\n",
    "    plt.savefig(os.path.join(PLOTS_PATH, \"_\".join(fp.split())))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(20,10), ncols=len(years), sharey=True)\n",
    "for year, ax in tqdm(zip(years.index, axes.flatten()), leave=False, position=0):\n",
    "    values = df[df[\"year\"]==year][\"statement_cleaned_v2\"].values\n",
    "    lens = [len(statement.split()) for statement in values]\n",
    "    ax.boxplot(lens)\n",
    "    ax.set_title(f\"{int(year)}\\n {len(values)} statement/s\")\n",
    "    sns.despine(ax=ax)\n",
    "fig.text(x=.5, y=.98, s=\"Distribution of number of words in statements by year\", ha=\"center\")\n",
    "plt.tight_layout(pad=2)\n",
    "plt.savefig(os.path.join(\n",
    "    PLOTS_PATH,\n",
    "    \"Distribution_Number_of_Words_By_Years\"),\n",
    "            dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modern_slavery",
   "language": "python",
   "name": "modern_slavery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
